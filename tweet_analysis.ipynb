{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOqrAMInjVrvmdm5dl6BJpM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Eiqhl5eRwpRK","executionInfo":{"status":"ok","timestamp":1651032907809,"user_tz":420,"elapsed":6997146,"user":{"displayName":"Apollo Callero","userId":"05789590555630948143"}},"outputId":"80004814-8203-4dfe-8b73-edb2c0915384"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","938/938 [==============================] - 560s 594ms/step - loss: 0.5099 - accuracy: 0.7484\n","model  ('nn0', <keras.engine.sequential.Sequential object at 0x7f1e4a98ae50>) added\n","938/938 [==============================] - 584s 620ms/step - loss: 0.5090 - accuracy: 0.7489\n","model  ('nn1', <keras.engine.sequential.Sequential object at 0x7f1e382b8090>) added\n","938/938 [==============================] - 587s 623ms/step - loss: 0.5057 - accuracy: 0.7516\n","model  ('nn2', <keras.engine.sequential.Sequential object at 0x7f1e2021fe10>) added\n","938/938 [==============================] - 616s 654ms/step - loss: 0.5077 - accuracy: 0.7489\n","model  ('nn3', <keras.engine.sequential.Sequential object at 0x7f1e3fbf8f90>) added\n","938/938 [==============================] - 591s 627ms/step - loss: 0.5051 - accuracy: 0.7498\n","model  ('nn4', <keras.engine.sequential.Sequential object at 0x7f1e4c841e90>) added\n","938/938 [==============================] - 579s 615ms/step - loss: 0.5062 - accuracy: 0.7527\n","model  ('nn5', <keras.engine.sequential.Sequential object at 0x7f1e4a803450>) added\n","938/938 [==============================] - 574s 608ms/step - loss: 0.5044 - accuracy: 0.7521\n","model  ('nn6', <keras.engine.sequential.Sequential object at 0x7f1e380da610>) added\n","938/938 [==============================] - 564s 598ms/step - loss: 0.5032 - accuracy: 0.7532\n","model  ('nn7', <keras.engine.sequential.Sequential object at 0x7f1e473b2c50>) added\n","938/938 [==============================] - 559s 593ms/step - loss: 0.5066 - accuracy: 0.7502\n","model  ('nn8', <keras.engine.sequential.Sequential object at 0x7f1e196df850>) added\n","938/938 [==============================] - 559s 593ms/step - loss: 0.5062 - accuracy: 0.7517\n","model  ('nn9', <keras.engine.sequential.Sequential object at 0x7f1e4a6b0d50>) added\n","0 th prediction made\n","100 th prediction made\n","200 th prediction made\n","300 th prediction made\n","400 th prediction made\n","500 th prediction made\n","600 th prediction made\n","700 th prediction made\n","800 th prediction made\n","900 th prediction made\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["#import librarys and mount drive\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","import nltk\n","import gensim\n","from gensim.models import Word2Vec as w2v\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Sequential\n","from keras.layers import Embedding , Dense , GRU\n","!pip install tensorflow\n","import tensorflow as tf\n","from sklearn.metrics import confusion_matrix , accuracy_score\n","import seaborn as sns\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing.text import Tokenizer\n","drive.mount('/content/drive')\n","DATASET_PATH = '/content/drive/MyDrive/437_semester_project/training_1600000.csv'\n","\n","#load in dataset into 1 massive pandas dataframe\n","big_df = pd.read_csv(DATASET_PATH,encoding = 'latin',header=None)\n","\n","#drop useless columns and relabel the labels\n","big_df = big_df.drop([1,2,3,4],axis = 1)\n","big_df = big_df.rename(columns={0:'label', 5:'text'})\n","big_df['label'] = big_df['label'].replace([4],1)\n","\n","#make a smaller balanced df and jumble it up\n","neg_df = big_df[big_df['label'] == 0].iloc[:750000]\n","pos_df = big_df[big_df['label'] == 1].iloc[:750000]\n","small_df = pd.concat([neg_df,pos_df])\n","small_df = small_df.sample(frac=1).reset_index(drop=True)\n","def remove_stop_words(df):\n","  '''\n","  df: pandas dataframe with unproccessed tweets\n","  returns the same df with stop words removed\n","  '''\n","  nltk.download(\"stopwords\")\n","  from nltk.corpus import stopwords\n","  sw = stopwords.words(\"english\")\n","  new_text = pd.DataFrame(df[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw)))\n","  df.text = new_text\n","  return df\n","stem_module = nltk.stem.PorterStemmer()\n","def stemmer(tweet):\n","  words = []\n","  tweet = tweet.split(\" \")\n","  for word in tweet:\n","    #add tag\n","    if len(word) == 0:\n","      continue\n","    if word[0] == '@':\n","      words.append('___TAG____')\n","    #add link\n","    elif word[0:4] == 'http':\n","      words.append('___LINK___')\n","    #add stemmed word with special chars\n","    else:\n","      word = ''.join(filter(str.isalnum, word))\n","      words.append(stem_module.stem(word).lower().strip())\n","  return \" \".join(words)\n","\n","\n","proccessed_df = remove_stop_words(small_df)\n","proccessed_df.text = proccessed_df.text.apply(lambda tweet: stemmer(tweet))\n","\n","def to_2d(text):\n","    '''\n","      utility function that makes a string sentence into\n","       a 2d list of words\n","    '''\n","    words = []\n","    text = text.split(\" \")\n","    for word in text:\n","      words.append(word)\n","    return words\n","\n","#make tokenizer\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(proccessed_df['text'].apply(lambda text:  to_2d(text)))\n","\n","#get seperate train/test/validation sets\n","\n","\n","def get_train_test_validation(df,max_tweet_words=280):\n","    #get a train , test and validation dataset \n","    y = df['label']\n","    X = df.copy()#.drop(['is_automated'] , axis = 1)\n","    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n","    train_indexs  = sss.split(X, y)\n","    for train_index, test_index in sss.split(X, y):\n","        train_set = df.iloc[train_index]\n","        test_valid_set = df.iloc[test_index]\n","    test_split = StratifiedShuffleSplit(n_splits=1, test_size=0.5)\n","    for test_index, valid_index in test_split.split(test_valid_set, test_valid_set['label']):\n","        test_set = test_valid_set.iloc[test_index]\n","        valid_set = test_valid_set.iloc[valid_index]\n","    #get y output labels and make X be a tokenized list\n","    y_train = np.array(train_set['label'])\n","    x_train = tokenizer.texts_to_sequences(train_set['text'])\n","    x_train = pad_sequences(x_train,maxlen=280)\n","    y_test = np.array(test_set['label'])\n","    x_test = tokenizer.texts_to_sequences(test_set['text'])\n","    x_test = pad_sequences(x_test,maxlen=280)\n","    y_valid = np.array(valid_set['label'])\n","    x_valid = tokenizer.texts_to_sequences(valid_set['text'])\n","    x_valid = pad_sequences(x_valid,maxlen=280)\n","    y_train = y_train.reshape(y_train.shape[0],)\n","    y_test = y_test.reshape(y_test.shape[0],)\n","    y_valid = y_valid.reshape(y_valid.shape[0],)\n","    return np.array(y_train),x_train,y_valid,x_valid,y_test,x_test\n","y_train,x_train,y_valid,x_valid,y_test,x_test = get_train_test_validation(proccessed_df)\n","\n","max_locs = np.where(x_train == np.amax(x_train))\n","num_words = x_train[max_locs[0][0]][max_locs[1][0]]\n","\n","def train_model(X_train,Y_train):\n","  '''\n","  x_train: tokenized and padded\n","  y_train: labels\n","  '''\n","  model = Sequential()\n","  model.add(Embedding(num_words+1, 100,input_length=280))#moves words 'closer togther'\n","  model.add(GRU(units=32))\n","  model.add(Dense(1,activation='sigmoid'))\n","  model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n","  model.fit(X_train,Y_train,verbose = 1,batch_size=128)\n","  return model\n","\n","#get 10 different portions of x_train and y_train\n","NUM_NN_MODELS = 10\n","x_trains = np.split(x_train,NUM_NN_MODELS)\n","y_trains = np.split(y_train,NUM_NN_MODELS)\n","\n","nn_models = []\n","model = None\n","for i in range(0,NUM_NN_MODELS):\n","  model_x_train = x_trains[i]\n","  model_y_train = y_trains[i]\n","  model_name = 'nn' + str(i)\n","  model = train_model(model_x_train,model_y_train)\n","  nn_models.append((model_name,model))\n","  print('model ' , nn_models[-1] , 'added')\n","\n","def make_predictions(nn_models, x_valid):\n","  predictions = []\n","  for i in range(x_valid.shape[0]):\n","    tweet = x_valid[i]\n","    tweet = tweet.reshape(1,280)\n","    sum = 0\n","    for model in nn_models:\n","      sum += model[1].predict([tweet])\n","    if sum / len(nn_models) > .5:\n","      predictions.append(1)\n","    else:\n","      predictions.append(0)\n","    if i % 100 == 0:\n","      print(i ,'th prediction made')\n","  return predictions\n","\n","predictions = make_predictions(nn_models, x_valid[:1000])\n","cf_matrix = confusion_matrix(y_valid[:1000],predictions)\n","ax = sns.heatmap(cf_matrix, annot=True, fmt=\"d\" , cbar_kws={\"orientation\": \"horizontal\"})"]}]}